I"7o<p>Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 네 번째 코스인 <a href="https://www.coursera.org/learn/feature-engineering/home/welcome">Feature Engineering</a>의 강의노트입니다.</p>

<hr />

<p><br /></p>

<h2 id="raw-data-to-feature">Raw Data to Feature</h2>

<hr />

<ul>
  <li>Feature Engineering
    <ul>
      <li>Scale to large datasets</li>
      <li>Find good features</li>
      <li>Preprocess with Cloud MLE</li>
    </ul>
  </li>
  <li>What raw data do we need to collect to predict the price of a house?
    <ul>
      <li>Lot Size</li>
      <li>Number of Rooms</li>
      <li>Location</li>
      <li>…</li>
    </ul>
  </li>
  <li>Raw data must be mapped into <code class="language-plaintext highlighter-rouge">numerical feature vectors</code></li>
</ul>

<p><br /></p>

<h2 id="good-vs-bad-features">Good vs Bad Features</h2>

<hr />

<ul>
  <li>What makes a good feature?
    <ol>
      <li>Be <code class="language-plaintext highlighter-rouge">related</code> to the objective</li>
      <li>Be known at <code class="language-plaintext highlighter-rouge">prediction-time</code></li>
      <li>Be <code class="language-plaintext highlighter-rouge">numeric</code> with <code class="language-plaintext highlighter-rouge">meaningful magnitude</code></li>
      <li>Have <code class="language-plaintext highlighter-rouge">enough examples</code></li>
      <li>Bring <code class="language-plaintext highlighter-rouge">human insight</code> to problem</li>
    </ol>
  </li>
  <li>Different problems in the same domain may need <code class="language-plaintext highlighter-rouge">different features</code></li>
  <li>Some data could be known <code class="language-plaintext highlighter-rouge">immediately</code>, and some other data is not known in real time</li>
  <li>You cannot train with current data and predict with <code class="language-plaintext highlighter-rouge">stale data</code></li>
  <li>Avoid having values of which you don’t have <code class="language-plaintext highlighter-rouge">enough examples</code></li>
</ul>

<p><br /></p>

<h2 id="representing-features">Representing Features</h2>

<hr />

<ul>
  <li>
    <p>Raw data are converted to numeric features in different ways</p>
  </li>
  <li>
    <p>Numeric values can be used <code class="language-plaintext highlighter-rouge">as-is</code> (real value)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">Overly specific</code> attributes should be <code class="language-plaintext highlighter-rouge">discarded</code></p>
  </li>
  <li>
    <p>Categorical variables should be <code class="language-plaintext highlighter-rouge">one-hot encoded</code></p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
  <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_coulmn_with_vocabulary_list</span><span class="p">(</span>
  <span class="err">​</span>		<span class="s">'employeeId'</span><span class="p">,</span>
  <span class="err">​</span>		<span class="n">Vocabulary_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'8345'</span><span class="p">,</span> <span class="s">'72365'</span><span class="p">,</span> <span class="s">'87654'</span><span class="p">,</span> <span class="s">'23451'</span><span class="p">])</span>
  </code></pre></figure>

<ul>
  <li>
    <p>Preprocess data to create a <code class="language-plaintext highlighter-rouge">vocabulary</code> of keys</p>

    <ul>
      <li>The vocabulary and the mapping of the vocabulary needs to be <code class="language-plaintext highlighter-rouge">identical at prediction time</code></li>
    </ul>
  </li>
  <li>
    <p>Options for encoding categorical data</p>

    <ul>
      <li>If you know the keys beforehand:</li>
    </ul>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">    <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_coulmn_with_vocabulary_list</span><span class="p">(</span>
    <span class="err">​</span>    		<span class="s">'employeeId'</span><span class="p">,</span>
    <span class="err">​</span>    		<span class="n">Vocabulary_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'8345'</span><span class="p">,</span> <span class="s">'72365'</span><span class="p">,</span> <span class="s">'87654'</span><span class="p">,</span> <span class="s">'23451'</span><span class="p">])</span>
    </code></pre></figure>

<ul>
  <li>
    <p>If your data is already indexed; i.e., has integers in[0-N):</p>

    <p>tf.feature_column.categorical_coulmn_with_identity( ‘employeeId’, num_bucket = 5)</p>
  </li>
  <li>
    <p>If you don’t have a vocabulary of all possible values:</p>

    <p>tf.feature_column.categorical_coulmn_with_hash_bucket( ‘employeeId’, hash_bucket_size = 500)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">Don't mix</code> magic number with data</p>
  </li>
</ul>

<p><br /></p>

<h2 id="ml-vs-statistics">ML vs Statistics</h2>

<hr />

<ul>
  <li><code class="language-plaintext highlighter-rouge">ML</code> = lots of data, keep outliers and build models for them</li>
  <li><code class="language-plaintext highlighter-rouge">Statistics</code> = “I’ve got all the data I’ll ever get”, throw away outliers</li>
  <li>Exact floats are not meaningful
    <ul>
      <li>Discretize floating point values into <code class="language-plaintext highlighter-rouge">bins</code></li>
    </ul>
  </li>
  <li>Crazy outliers will hurt trainability</li>
  <li>Ideally, features should have a similar range (Typically [0, 1] or [-1, 1])</li>
</ul>

<p><br /></p>

<h2 id="preprocessing-feature-creation">Preprocessing Feature Creation</h2>

<hr />

<ul>
  <li>Feature engineering often requires global statistics and vocabularies</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">features</span><span class="p">[</span><span class="s">'scaled_price'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span> <span class="o">-</span> <span class="n">min_price</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">max_price</span> <span class="o">-</span> <span class="n">min_price</span><span class="p">)</span>

  <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_column_with_vocabulary_list</span><span class="p">(</span><span class="s">'city'</span><span class="p">,</span>
  <span class="err">​</span>	<span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s">'San Diego'</span><span class="p">,</span> <span class="s">'Los Angeles'</span><span class="p">,</span> <span class="s">'San Francisco'</span><span class="p">,</span> <span class="s">'Sacramento'</span><span class="p">])</span>
  </code></pre></figure>

<ul>
  <li>
    <p>Things that are commonly done in preprocessing (In TensorFlow)</p>

    <ul>
      <li>Scaling, discretization, etc. of numeric features</li>
      <li>Splitting, lower-casing, etc. of textual features</li>
      <li>Resizing of input images</li>
      <li>Normalizing volume level of input audio</li>
    </ul>
  </li>
  <li>
    <p>There are two places for feature creation in TensorFlow</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">   <span class="mf">1.</span> <span class="n">Features</span> <span class="n">are</span> <span class="n">preprocessed</span> <span class="ow">in</span> <span class="n">input_FN</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="nb">eval</span><span class="p">,</span> <span class="n">serving</span><span class="p">)</span>

  <span class="n">features</span><span class="p">[</span><span class="s">'capped_rooms'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">clip_by_value</span><span class="p">(</span>
  <span class="err">​</span>	<span class="n">features</span><span class="p">[</span><span class="s">'rooms'</span><span class="p">],</span>
  <span class="err">​</span>	<span class="n">clip_value_min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
  <span class="err">​</span>	<span class="n">clip_value_max</span><span class="o">=</span><span class="mi">4</span>
  <span class="p">}</span>

  <span class="c1"># 2. Feature columns are passed into the estimator during construction
</span>  <span class="n">lat</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">numeric_column</span><span class="p">(</span><span class="s">'latitude'</span><span class="p">)</span>
  <span class="n">dlat</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">bucketized_column</span><span class="p">(</span><span class="n">lat</span><span class="p">,</span>
  <span class="err">​</span>	<span class="n">boundaries</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">42</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="n">tolist</span><span class="p">())</span>
   </code></pre></figure>

<p><br /></p>

<h2 id="feature-cross">Feature Cross</h2>

<hr />

<ul>
  <li>Using non-linear inputs in a linear learner</li>
  <li>Dividing the input space with two lines yields four quadrants</li>
  <li>The weight of a cell is essentially the prediction for that cell</li>
  <li>Feature crosses <code class="language-plaintext highlighter-rouge">memorize</code></li>
  <li>Goal of ML is <code class="language-plaintext highlighter-rouge">generalization</code></li>
  <li>Memorization works when you have <code class="language-plaintext highlighter-rouge">lots of data</code></li>
  <li>Feature crosses bring a lot of power to linear models
    <ul>
      <li>Feature crosses + <code class="language-plaintext highlighter-rouge">massive data</code> is an efficient way for learning highly complex spaces</li>
      <li>Feature crosses allow a linear model to memorize large datasets</li>
      <li>Optimizing linear models is a convex problem</li>
      <li>Feature crosses,as a preprocessor, make neural networks converge a lot quicker</li>
    </ul>
  </li>
  <li>Feature crosses combine <code class="language-plaintext highlighter-rouge">discrete</code> / <code class="language-plaintext highlighter-rouge">categorical</code> features</li>
  <li>Feature Crosses lead to <code class="language-plaintext highlighter-rouge">sparsity</code></li>
</ul>

<p><br /></p>

<h2 id="implementing-feature-crosses">Implementing Feature Crosses</h2>

<hr />

<ul>
  <li>Creating feature crosses using TensorFlow</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">day_hr</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">crossed_column</span><span class="p">([</span><span class="n">dayofweek</span><span class="p">,</span> <span class="n">hourofday</span><span class="p">],</span> <span class="mi">24</span><span class="o">*</span><span class="mi">7</span><span class="p">)</span>
  </code></pre></figure>

<ul>
  <li>
    <p>Choosing the number of hash buckets is an art, not a science</p>
  </li>
  <li>
    <p>The number of hash buckets controls sparsity and collisions</p>

    <ul>
      <li>Small hash_buckets → lots of collisions</li>
      <li>High hash_buckets → very sparse</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="embedding-feature-crosses">Embedding Feature Crosses</h2>

<hr />

<ul>
  <li>Creating an <code class="language-plaintext highlighter-rouge">embedding column</code> from a feature cross</li>
  <li>The <code class="language-plaintext highlighter-rouge">weights</code> in the embedding column are learned from data</li>
  <li>The model learns how to embed the feature cross in lower-dimensional space</li>
</ul>

<p><br /></p>

<h2 id="where-to-do-feature-engineering">Where to Do Feature Engineering</h2>

<hr />

<ul>
  <li>
    <p>Three possible places to do feature engineering</p>

    <ul>
      <li>TensorFlow feature_column input_fn</li>
      <li>Dataflow</li>
      <li>Dataflow + TensorFlow (tf.transform)</li>
    </ul>

    <p><img src="/assets/img/posts/feature-engineering/01.png" alt="Three possible places to do feature engineering" class="center-75" /><br />
<span class="caption">Three possible places to do feature engineering</span></p>
  </li>
  <li>
    <p>Some preprocessing can be done in <code class="language-plaintext highlighter-rouge">tf.feature_column</code></p>
  </li>
  <li>
    <p>Powerful preprocessing can be done in TensorFlow by creating a new feature column</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">latbuckets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">38.0</span><span class="p">,</span> <span class="mf">42.0</span><span class="p">,</span> <span class="n">nbuckets</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
  <span class="n">lonbuckets</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">76.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">72.0</span><span class="p">,</span> <span class="n">nbuckets</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>

  <span class="n">b_lat</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">bucketized_column</span><span class="p">(</span><span class="n">house_lat</span><span class="p">,</span> <span class="n">latbuckets</span><span class="p">)</span>
  <span class="n">b_lon</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">bucketized_column</span><span class="p">(</span><span class="n">house_lon</span><span class="p">,</span> <span class="n">lonbuckets</span><span class="p">)</span>

  <span class="c1"># feature cross and embed
</span>  <span class="n">loc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">crossed_column</span><span class="p">(</span><span class="n">house_lat</span><span class="p">,</span> <span class="n">latbuckets</span><span class="p">)</span>

  <span class="n">eloc</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">embedding_column</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">nbuckets</span><span class="o">//</span><span class="mi">4</span><span class="p">)</span>
  </code></pre></figure>

<p><br /></p>

<h2 id="feature-creation-in-tensorflow">Feature Creation in TensorFlow</h2>

<hr />

<ul>
  <li>Create new features from existing features in TensorFlow</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="k">def</span> <span class="nf">add_engineered</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
  <span class="err">​</span>	<span class="n">lat1</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s">'lat'</span><span class="p">]</span>
  <span class="err">​</span>	<span class="n">lat2</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="s">'metro_lat'</span><span class="p">]</span>
  <span class="err">​</span>	<span class="n">latdiff</span> <span class="o">=</span> <span class="n">lat1</span> <span class="o">-</span> <span class="n">lat2</span>
  <span class="err">​</span>	<span class="p">...</span>
  <span class="err">​</span>	<span class="n">dist</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">latdiff</span><span class="o">*</span><span class="n">latdiff</span> <span class="o">+</span> <span class="n">londiff</span><span class="o">*</span><span class="n">londiff</span><span class="p">)</span>
  <span class="err">​</span>	<span class="n">features</span><span class="p">[</span><span class="s">'euclidean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dist</span>
  <span class="err">​</span>	<span class="k">return</span> <span class="n">features</span>
  </code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="k">def</span> <span class="nf">train_input_fn</span><span class="p">():</span>
  <span class="err">​</span>	<span class="p">...</span>
  <span class="err">​</span>	<span class="n">features</span> <span class="o">=</span> <span class="p">...</span>
  <span class="err">​</span>	<span class="k">return</span> <span class="n">add_engineered</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">label</span>

  <span class="k">def</span> <span class="nf">serving_input_fn</span><span class="p">():</span>
  <span class="err">​</span>	<span class="p">...</span>
  <span class="err">​</span>	<span class="k">return</span> <span class="n">ServingInputReceiver</span><span class="p">(</span>
  <span class="err">​</span>								<span class="n">add_engineered</span><span class="p">(</span><span class="n">features</span><span class="p">),</span>
  <span class="err">​</span>								<span class="n">json_features_ph</span><span class="p">)</span>
  </code></pre></figure>

<p><br /></p>

<h2 id="tensorflow-transform">TensorFlow Transform</h2>

<hr />

<ul>
  <li>Pros and Cons of three ways to do feature engineering</li>
</ul>

<p><img src="/assets/img/posts/feature-engineering/02.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.transform</code> is a hybrid of Beam and TensorFlow</li>
  <li><code class="language-plaintext highlighter-rouge">Analyze</code> - Beam
    <ul>
      <li>Find min/max value of numeric feature</li>
      <li>Find all the unique values of a categorical feature</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Transform</code> - TensorFlow
    <ul>
      <li>Scale inputs by the min &amp; max</li>
      <li>One-hot encode inputs based on set of unique values</li>
    </ul>
  </li>
  <li>tf.transform provides two PTransforms
    <ul>
      <li><code class="language-plaintext highlighter-rouge">AnalyzeAndTransformDataset</code> - Executed in Beam to create the training dataset</li>
      <li><code class="language-plaintext highlighter-rouge">TransformDataset</code> - Executed in Beam to create the evaluation dataset / The underlying transformations are executed in TensorFlow at prediction time</li>
    </ul>
  </li>
  <li>tf.transform has two phases
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Analysis phase</code> (compute min/max/vocab etc. using Beam) Executed in Beam while creating training dataset</li>
      <li><code class="language-plaintext highlighter-rouge">Transform phase</code> (scale/vocabulary etc. using TensorFlow) Executed in TensorFlow during prediction Executed in Beam to create training/evaluation datasets</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="analysis-phase">Analysis phase</h2>

<hr />

<ul>
  <li>First, set up the <code class="language-plaintext highlighter-rouge">schema</code> of the training dataset</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">raw_data_schema</span> <span class="o">=</span> <span class="p">{</span>
  <span class="err">​</span>	<span class="n">colname</span> <span class="p">:</span> <span class="n">dataset_schema</span><span class="p">.</span><span class="n">ColumnSchema</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">,</span> <span class="p">...)</span>
  <span class="err">​</span>		<span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="s">'datofweek,key'</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">','</span><span class="p">)</span>
  <span class="p">}</span>
  <span class="n">raw_data_schema</span><span class="p">.</span><span class="n">update</span><span class="p">({</span>
  <span class="err">​</span>	<span class="n">colname</span> <span class="p">:</span> <span class="n">dataset_schema</span><span class="p">.</span><span class="n">ColumnSchema</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">...)</span>
  <span class="err">​</span>		<span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="s">'fare_amount,pickuplon,...,dropofflat'</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">','</span><span class="p">)</span>
  <span class="p">})</span>
  <span class="n">raw_data_metadata</span> <span class="o">=</span> 
  <span class="err">​</span>	<span class="n">dataset_metadata</span><span class="p">.</span><span class="n">DatasetMetadata</span><span class="p">(</span><span class="n">dataset_schema</span><span class="p">.</span><span class="n">Schema</span><span class="p">(</span><span class="n">raw_data_schema</span><span class="p">))</span>
   </code></pre></figure>

<ul>
  <li>Next, run the <code class="language-plaintext highlighter-rouge">analyze-and-transform</code> PTransform on training dataset to get back preprocessed training data and the transform function</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">raw_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span> <span class="c1"># 1.Read in data as usual for Beam
</span>  <span class="err">​</span>	<span class="o">|</span> <span class="n">beam</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">Read</span><span class="p">(</span><span class="n">beam</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">BigQuerySource</span><span class="p">(</span><span class="n">query</span><span class="o">=</span><span class="n">myquery</span><span class="p">,</span> <span class="n">use_standard_sql</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
  <span class="err">​</span>	<span class="o">|</span> <span class="n">beam</span><span class="p">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">is_valid</span><span class="p">))</span> <span class="c1"># 2. Filter out data that you don't want to train with
</span>
  <span class="c1"># 3. Pass raw data + metadata template to AnalyzeAndTransformDataset
</span>  <span class="c1"># 4. Get back transformed dataset and a reusable transform function
</span>  <span class="n">transformed_dataset</span><span class="p">,</span> <span class="n">transform_fn</span> <span class="o">=</span> <span class="p">((</span><span class="n">raw_data</span><span class="p">,</span> <span class="n">raw_data_metadata</span><span class="p">)</span>
  <span class="err">​</span>	<span class="o">|</span> <span class="n">beam_impl</span><span class="p">.</span><span class="n">AnalyzeAndTransformDataset</span><span class="p">(</span><span class="n">preprocess</span><span class="p">))</span> </code></pre></figure>

<ul>
  <li>Write out the preprocessed training data into <code class="language-plaintext highlighter-rouge">TFRecords</code>, the most efficient format for TensorFlow</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="n">transformed_data</span> <span class="o">|</span>
  <span class="err">​</span>	<span class="n">tf</span><span class="p">.</span><span class="n">recordio</span><span class="p">.</span><span class="n">WriteToTFRecord</span><span class="p">(</span>
  <span class="err">​</span>		<span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="s">'train'</span><span class="p">),</span>

  <span class="err">​</span>		<span class="n">coder</span><span class="o">=</span><span class="n">ExampleProtoCoder</span><span class="p">(</span>
  <span class="err">​</span>				<span class="n">transformed_metadata</span><span class="p">.</span><span class="n">schema</span><span class="p">)</span>

   </code></pre></figure>

<p><br /></p>

<h2 id="transform-phase">Transform phase</h2>

<hr />

<ul>
  <li>The preprocessing function is restricted to TensorFlow function you can call from TensorFlow graph</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python">  <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
  <span class="err">​</span>	<span class="n">result</span> <span class="o">=</span> <span class="p">{}</span> <span class="c1"># Create features from the input tensors and put into "results" dict
</span>  <span class="err">​</span>	<span class="n">result</span><span class="p">[</span><span class="s">'fare_amount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s">'fare_amount'</span><span class="p">]</span> <span class="c1"># Pass through
</span>  <span class="err">​</span>	<span class="n">result</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tft</span><span class="p">.</span><span class="n">string_to_int</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">])</span> <span class="c1"># vocabulary
</span>  <span class="err">​</span>	<span class="p">...</span>
  <span class="err">​</span>	<span class="n">retult</span><span class="p">[</span><span class="s">'dropofflat'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">tft</span><span class="p">.</span><span class="n">scale_to_0_1</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">'dropofflat'</span><span class="p">]))</span> <span class="c1"># scaling
</span>  <span class="err">​</span>	<span class="n">result</span><span class="p">[</span><span class="s">'passengers'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">'passengers'</span><span class="p">],</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># Other TF fns
</span>  <span class="err">​</span>	<span class="k">return</span> <span class="n">result</span> 
   </code></pre></figure>

<ul>
  <li>Writing out the eval dataset is similar,except that we reuse the transform function computed from the training data</li>
</ul>
:ET