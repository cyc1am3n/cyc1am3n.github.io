<!DOCTYPE html>
<html lang="en">
<head>
  <!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Machine Learning] Multivariate Linear Regression | Daeyoung Kim</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="[Machine Learning] Multivariate Linear Regression" />
<meta name="author" content="cyc1am3n" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다." />
<meta property="og:description" content="* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다." />
<link rel="canonical" href="http://localhost:4000/2018/02/09/multivariate-linear-regression.html" />
<meta property="og:url" content="http://localhost:4000/2018/02/09/multivariate-linear-regression.html" />
<meta property="og:site_name" content="Daeyoung Kim" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-02-09T15:01:54+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[Machine Learning] Multivariate Linear Regression" />
<meta name="twitter:site" content="@daeyoung__k" />
<meta name="twitter:creator" content="@cyc1am3n" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"cyc1am3n"},"dateModified":"2018-02-09T15:01:54+09:00","datePublished":"2018-02-09T15:01:54+09:00","description":"* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다.","headline":"[Machine Learning] Multivariate Linear Regression","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/02/09/multivariate-linear-regression.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/smile.png"},"name":"cyc1am3n"},"url":"http://localhost:4000/2018/02/09/multivariate-linear-regression.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav>
      <ul>
        
        <!-- others -->
        <a href="/">
          <li class="btn-nav">Home</li>
        </a>
        
        
        
          <a href="/blog">
            <li class="current btn-nav">Blog</li>
          </a>
          <a href="/tags">
            <li class="btn-nav">Tags</li>
          </a>
        
        
      </ul>
    </nav>
  </header>
</section>
<div id="post">
  <section class="post-header">
    <h1 class="title">[Machine Learning] Multivariate Linear Regression</h1>
    <p class="subtitle">「 Machine Learning 」 lecture summary #4</p>
    <p class="meta">
      February 9, 2018
    </p>
  </section>
  <section class="post-content">
    <p>* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 <a href="https://www.coursera.org/learn/machine-learning">Machine Learning(링크)</a>를 바탕으로 작성되었습니다.</p>

<h2 id="multiple-feature">Multiple Feature</h2>

<p>Data set의 feature가 여러 개인 경우의 Linear Regression을 <code class="language-plaintext highlighter-rouge">Multivariate Linear Regression</code>이라고 한다.</p>

<p>집 값 예측하기에 빗대어 설명하면 집의 크기 외에도 마당의 크기, 편의시설과 가까운 정도 등 다른 요인까지 생각했다고 보면 된다.(h(x)가 linear 하다고 했을 때.)</p>

<p>앞으로 나올 용어 정리를 하자면 x<sub>j</sub><sup>(i)</sup> = i번째 training example의 j번째 feature 값 이고,</p>

<p>h(x)는 다음과 같다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-1.png" alt="그림1" width="75%" height="75%" /></p>

<p>feature가 n개 이지만 vectorization을 위해 θ<sub>0</sub> = θ<sub>0</sub>x<sub>0</sub>, 즉 x<sub>0</sub> = 1 이라 하면 h(x)는 이렇게도 표현이 가능하다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-2.png" alt="그림2" width="75%" height="75%" /></p>

<p>이제 행렬 연산으로 h(x)를 간편하게 계산할 수 있게 되었다.</p>

<h2 id="gradient-descent-for-multiple-variables">Gradient Descent For Multiple Variables</h2>

<p>multiple variables 일때도 gradient descent 방정식은 형태가 같다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-3.png" alt="그림3" width="65%" height="65%" /></p>

<p>즉,</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-4.png" alt="그림4" width="75%" height="75%" /></p>

<p>이다.</p>

<p>다음은 feature 가 1개 일 때와 여러 개 일때 gradient descent algorithm을 비교한 것이다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-5.png" alt="그림5" width="75%" height="75%" /></p>

<h2 id="feature-scaling">Feature Scaling</h2>

<p><code class="language-plaintext highlighter-rouge">input value의 범위를 일치</code>시키면 좀 더 빨리 gradient descent를 구할 수 있다.</p>

<p>input value가 고르지 못할 때, 작은 범위에서는 θ가 천천히 변하고 큰 범위에서는 θ가 빨리 변하게 되므로 비효율적으로 진동하게 되기 때문이다.</p>

<p>보통 정규화를 시켜서 늘리거나 줄이는데, 범위만 일치시키면 크게 문제는 없다.</p>

<p>-1 ≤ x<sub>i</sub> ≤ 1 이나 -0.5 ≤ x<sub>i</sub> ≤ 0.5 등 이렇게 설정해도 상관은 없는데 모든 변수에만 똑같이 적용시키면 된다는 뜻이다.</p>

<p>보통은 다음과 같이 정규화시킨다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-6.png" alt="그림6" width="25%" height="25%" /></p>

<p>여기서 μ<sub>i</sub>은 해당 i번째 feature의 평균값이고, s<sub>i</sub>는 해당 i번째 feature 중에서 최대값과 최소값을 뺀 만큼의 값이다.</p>

<p>예를 들어서 price라는 feature가 100~2000 사이의 값을 가지고 있고 평균값이 1000이라면,</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-7.png" alt="그림7" width="25%" height="25%" /></p>

<p>이다.</p>

<h2 id="learning-rate">Learning Rate</h2>

<p>gradient descent를 이용해서 θ를 구할 때, Cost function 즉 J(θ)가 매 반복마다 줄어야한다.</p>

<p>보통 gradient descent에서 J(θ)가 iteration 한 번에 아주 작은 값(ex. 10<sup>-3</sup>) 보다 적게 줄어들면 <code class="language-plaintext highlighter-rouge">수렴</code>한다고 판단한다.</p>

<p>그런데 반복할 때 마다 J(θ)가 줄어들거나 수렴하지 않고 증가한다면 문제는 learning rate에 있다.</p>

<p>J(θ)가 너무 천천히 줄어드는 것 또한 learning rate 설정의 오류이다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-8.png" alt="그림8" width="70%" height="70%" /></p>

<p>요약하자면,</p>

<p>α가 너무 작다: 수렴하는 값을 찾는게 오래걸린다.<br />
α가 너무 크다: 매 반복마다 감소하지 않고 수렴하지 않는다.</p>

<h2 id="features-and-polynomial-regression">Features and Polynomial Regression</h2>

<p>주어진 data의 feature를 잘 분석하면 성능 향상에 도움이 되는데, <code class="language-plaintext highlighter-rouge">여러 개의 feature를 조합해 하나로 만들 수도 있다.</code></p>

<p>예를 들면, 집 값을 예측하기 위해 집의 frontage(x<sub>1</sub>), depth(x<sub>2</sub>)라는 feature가 있다고 했을 때 이 두 개를 곱한 area(x<sub>3</sub>=x<sub>1</sub>x<sub>2</sub>)라는 새로운 feature를 만들 수 있다는 말이다.</p>

<p>또한 Data set의 분포를 보고 그에 적합한 hypothsis function을 설정할 수 있는데, linear 뿐만 아니라 quadratic, cubic 또는 square root의 hypothesis function도 가능하다.</p>

<p style="text-align: center;"><img src="/assets/img/posts/multivariate-linear-regression/multivariate-linear-regression-9.png" alt="그림9" width="70%" height="70%" /></p>

<p>위의 그래프에서 size라는 feature를 가지고 hypothesis function을 설정하면 cubic한 다항식이 될 것이다.</p>

<p>이때 θ<sub>3</sub>x<sup>3</sup>에서 x를 세제곱을 했기 때문에 다른 항에 비해서 x값의 증가량에 비해 변화량이 크므로 feature scaling에 유의해야한다.</p>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href="https://cyc1am3n.github.io">Daeyoung Kim</a>.
  </div>
</footer>

  </div>
</body>

</html>