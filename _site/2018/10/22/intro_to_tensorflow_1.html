<!DOCTYPE html>
<html lang="en">
<head>
  <!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Coursera] Intro to TensorFlow (1) | Daeyoung Kim</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="[Coursera] Intro to TensorFlow (1)" />
<meta name="author" content="cyc1am3n" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 세 번째 코스인 Intro to TensorFlow의 1주차 강의노트입니다." />
<meta property="og:description" content="Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 세 번째 코스인 Intro to TensorFlow의 1주차 강의노트입니다." />
<link rel="canonical" href="http://localhost:4000/2018/10/22/intro_to_tensorflow_1.html" />
<meta property="og:url" content="http://localhost:4000/2018/10/22/intro_to_tensorflow_1.html" />
<meta property="og:site_name" content="Daeyoung Kim" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-22T20:00:54+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[Coursera] Intro to TensorFlow (1)" />
<meta name="twitter:site" content="@daeyoung__k" />
<meta name="twitter:creator" content="@cyc1am3n" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"cyc1am3n"},"dateModified":"2018-10-22T20:00:54+09:00","datePublished":"2018-10-22T20:00:54+09:00","description":"Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 세 번째 코스인 Intro to TensorFlow의 1주차 강의노트입니다.","headline":"[Coursera] Intro to TensorFlow (1)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/10/22/intro_to_tensorflow_1.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/smile.png"},"name":"cyc1am3n"},"url":"http://localhost:4000/2018/10/22/intro_to_tensorflow_1.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav>
      <ul>
        
        <!-- others -->
        <a href="/">
          <li class="btn-nav">Home</li>
        </a>
        
        
        
          <a href="/blog">
            <li class="current btn-nav">Blog</li>
          </a>
          <a href="/tags">
            <li class="btn-nav">Tags</li>
          </a>
        
        
      </ul>
    </nav>
  </header>
</section>
<div id="post">
  <section class="post-header">
    <h1 class="title">[Coursera] Intro to TensorFlow (1)</h1>
    <p class="subtitle">Machine Learning with TensorFlow on GCP</p>
    <p class="meta">
      October 22, 2018
    </p>
  </section>
  <section class="post-content">
    <p>Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 세 번째 코스인 <a href="https://www.coursera.org/learn/intro-tensorflow/home">Intro to TensorFlow</a>의 1주차 강의노트입니다.</p>

<hr />

<p><br /></p>

<h2 id="what-is-tensorflow">What is TensorFlow?</h2>

<hr />

<ul>
  <li>TensorFlow is an open-source high-performance library for <code class="language-plaintext highlighter-rouge">numerical computation</code> that uses <code class="language-plaintext highlighter-rouge">directed graphs</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">nodes</code> represent mathematical operations.(ex. add)</li>
  <li>The <code class="language-plaintext highlighter-rouge">edges</code> represent the input and output of mathematical operations.</li>
</ul>

<p><br /></p>

<h2 id="benefits--of-a-directed-graph">Benefits  of a Directed Graph</h2>

<hr />

<ul>
  <li>Directed acyclic graph(DAG) is a <code class="language-plaintext highlighter-rouge">language-independent</code> representation of the code in model.</li>
  <li>This makes graphs <code class="language-plaintext highlighter-rouge">being portable</code> between different devices.</li>
  <li>TensorFlow can <code class="language-plaintext highlighter-rouge">insert send and receive nodes</code> to distribute the graph across machines.</li>
  <li>TensorFlow can optimize the graph by <code class="language-plaintext highlighter-rouge">merging successive nodes</code> where necessary.</li>
  <li>TensorFlow Lite provides on-device inference of ML models on mobile devices and is available for a variety of hardware.</li>
  <li>TensorFlow supports <code class="language-plaintext highlighter-rouge">federated</code> learning.</li>
</ul>

<p><br /></p>

<h2 id="tensorflow-api-hierarchy">TensorFlow API Hierarchy</h2>

<hr />

<p><img src="/img/posts/intro-to-tensorflow/01.png" alt="TensorFlow tolkit hierarchy" class="center-75" /><br />
<span class="caption">TensorFlow tolkit hierarchy</span></p>

<ul>
  <li>The lowest level is a layer that’s implemented to target different hardware platforms.</li>
  <li>The next level is a TensorFlow C++ API.</li>
  <li>The core Python API is what contains much of the <code class="language-plaintext highlighter-rouge">numeric processing code</code>.</li>
  <li>Set of Python modules that have <code class="language-plaintext highlighter-rouge">high level representation</code> of useful NN components. (good for custom model)</li>
  <li><code class="language-plaintext highlighter-rouge">Estimator</code> knows how to training, evaluate, create a check point, save and serve model.</li>
</ul>

<p><br /></p>

<h2 id="lazy-evaluation">Lazy Evaluation</h2>

<hr />

<ul>
  <li>The Python API lets you <code class="language-plaintext highlighter-rouge">build and run</code> Directed Graphs</li>
  <li>Create the Graph (Build)</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">...</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>Run the Graph (Run)</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">numpy_c</span> <span class="o">=</span> <span class="n">session</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">...)</span></code></pre></figure>

<ul>
  <li>The graph definition is separate from the training loop because this is a lazy evaluation model. (need to run the graph to get results)</li>
  <li><code class="language-plaintext highlighter-rouge">tf.eager</code>, however, allows to execute operations imperatively.</li>
</ul>

<p><br /></p>

<h2 id="graph-and-session">Graph and Session</h2>

<hr />

<ul>
  <li><code class="language-plaintext highlighter-rouge">Graphs</code> can be processed, compiled, remotely executed, and assigned  to devices.</li>
  <li>The <code class="language-plaintext highlighter-rouge">edges</code> represent data as <code class="language-plaintext highlighter-rouge">tensor</code> which are n-dimensional arrays.</li>
  <li>The <code class="language-plaintext highlighter-rouge">nodes</code> represent TensorFlow <code class="language-plaintext highlighter-rouge">operations</code> on those tensors.</li>
  <li><code class="language-plaintext highlighter-rouge">Session</code> allows  TensorFlow to <code class="language-plaintext highlighter-rouge">cache and distribute</code> computation.</li>
</ul>

<p><img src="/img/posts/intro-to-tensorflow/02.png" alt="Session" class="center-75" /><br />
<span class="caption">Session</span></p>

<ul>
  <li>Execute TensorFlow graphs by calling <code class="language-plaintext highlighter-rouge">run()</code> on a <code class="language-plaintext highlighter-rouge">tf.Session</code></li>
</ul>

<p><br /></p>

<h2 id="evaluating-a-tensor">Evaluating a Tensor</h2>

<hr />

<ul>
  <li>It is possible to <code class="language-plaintext highlighter-rouge">evaluate</code> a list of tensors.</li>
  <li>TensorFlow in <code class="language-plaintext highlighter-rouge">Eager mode</code> makes it easier to try out things, but is not recommended for production code.</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.eager.python</span> <span class="kn">import</span> <span class="n">tfe</span>
<span class="n">tfe</span><span class="p">.</span><span class="n">enable_eager_execution</span><span class="p">()</span> <span class="c1"># Call exactly once
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># OUTPUT:
# tf.Tensor([2 3 4], shape=(3,), dtype=int32)</span></code></pre></figure>

<p><br /></p>

<h2 id="visualizing-a-graph">Visualizing a graph</h2>

<hr />

<ul>
  <li>You can write the graph out using <code class="language-plaintext highlighter-rouge">tf.summary.FileWriter</code></li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"x"</span><span class="p">)</span> <span class="c1"># Name the tensors and the operations
</span><span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"y"</span><span class="p">)</span>
<span class="n">z1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"z1"</span><span class="p">)</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="n">z3</span> <span class="o">=</span> <span class="n">z2</span> <span class="o">-</span> <span class="n">z1</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="c1"># Write the session graph to summary directory
</span><span class="err">​</span>	<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="s">'summaries'</span><span class="p">,</span> <span class="n">sess</span><span class="p">.</span><span class="n">graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
<span class="err">​</span>		<span class="n">a1</span><span class="p">,</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span><span class="n">z1</span><span class="p">,</span> <span class="n">z3</span><span class="p">])</span></code></pre></figure>

<p>Then,</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">!</span><span class="n">ls</span> <span class="n">summaries</span>
<span class="n">event</span><span class="p">.</span><span class="n">out</span><span class="p">.</span><span class="n">tfevents</span><span class="p">.</span><span class="mf">1517032067.e7</span><span class="n">cbb0325e48</span></code></pre></figure>

<p>It’s not human-readable.</p>

<ul>
  <li>The graph can be visualized in <code class="language-plaintext highlighter-rouge">TensorBoard</code>.</li>
</ul>

<p><br /></p>

<h2 id="tensors">Tensors</h2>

<hr />

<ul>
  <li>A tensor is an N-dimensional array of data.</li>
</ul>

<p><img src="/img/posts/intro-to-tensorflow/03.png" alt="what is tensor" class="center-75" /><br />
<span class="caption">what is tensor</span></p>

<ul>
  <li>Tensors can be <code class="language-plaintext highlighter-rouge">sliced</code></li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:.</span> <span class="mi">1</span><span class="p">]</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span> <span class="n">y</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># OUTPUT:
# [5 6]</span></code></pre></figure>

<ul>
  <li>Tensors can be <code class="language-plaintext highlighter-rouge">reshaped</code></li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span> <span class="n">y</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># OUTPUT:
# [[3 5]
#  [7 4]
#  [6 8]</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span> <span class="n">y</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># OUTPUT:
# [7 4]</span></code></pre></figure>

<p><br /></p>

<h2 id="variables">Variables</h2>

<hr />

<ul>
  <li>A variable is a tensor whose value is <code class="language-plaintext highlighter-rouge">initialized</code> and then typically <code class="language-plaintext highlighter-rouge">changed</code> as the program runs.</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="err">​</span>	<span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="err">​</span>	<span class="c1"># Create variable, specifying how to init and whether it can be tuned
</span><span class="err">​</span>	<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"model"</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">AUTO_REUSE</span><span class="p">):</span>
<span class="err">​</span>		<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"weights"</span><span class="p">,</span>
<span class="err">​</span>										<span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="c1"># 1 x 2 matrix
</span><span class="err">​</span>										<span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">truncated_normal_initializer</span><span class="p">(),</span>
<span class="err">​</span>										<span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="err">​</span>	<span class="c1"># "Training loop" of 5 updates to weights
</span><span class="err">​</span>	<span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="err">​</span>	<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">niter</span><span class="p">):</span>
<span class="err">​</span>		<span class="n">preds</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="err">​</span>		<span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="c1"># "Gradient Update"
</span><span class="err">​</span>	<span class="k">return</span> <span class="n">preds</span></code></pre></figure>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.get_variable</code> can be helpful to be able to reuse variables or create them afresh depending on different situations.</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="c1"># Multiplying [1,2] x [2,3] yields a [1,3] matrix
</span><span class="err">​</span>	<span class="n">preds</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">3.2</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">,</span> <span class="mf">7.2</span><span class="p">],[</span><span class="mf">4.3</span><span class="p">,</span> <span class="mf">6.2</span><span class="p">,</span> <span class="mf">8.3</span><span class="p">]]))</span> <span class="c1"># 2 x 3 matrix
</span><span class="err">​</span>	<span class="c1"># Initialize all variables
</span><span class="err">​</span>	<span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">().</span><span class="n">run</span><span class="p">()</span>
<span class="err">​</span>	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)):</span>
<span class="err">​</span>		<span class="k">print</span> <span class="s">"{}:{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">eval</span><span class="p">())</span>

<span class="c1"># OUTPUT:
# 0:[[-0.5322 -1.408 -2.3759]]
# 1:[[0.2177 -0.2780 -0.8259]]
# 2:[[0.9677 0.8519 0.724]]
# 3:[[1.7177 1.9769 2.2747]]
# 4:[[2.4677 3.1155 3.8245]]</span></code></pre></figure>

<ul>
  <li>To summarize,
    <ol>
      <li>create a variable by calling <code class="language-plaintext highlighter-rouge">get_variable</code></li>
      <li>decide on how to <code class="language-plaintext highlighter-rouge">initialize</code> a variable</li>
      <li>use the <code class="language-plaintext highlighter-rouge">variable</code> just like any other tensor when building the graph</li>
      <li>In session, <code class="language-plaintext highlighter-rouge">initialize</code> the variable</li>
      <li>evaluate any tensor that you want to evaluate</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Placeholders</code> allow you to feed in values, such as by reading from a text file</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">"float"</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">4</span>
<span class="k">print</span> <span class="n">a</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">a</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]}))</span>

<span class="c1"># OUTPUT:
# Tensor("Placeholder:0", dtype=float32)
# [4 8 12]</span></code></pre></figure>

<p><br /></p>

<h2 id="debugging-tensorflow-programs">Debugging TensorFlow programs</h2>

<hr />

<ul>
  <li>Debugging TensorFlow programs is <code class="language-plaintext highlighter-rouge">similar</code> to debugging any piece of software
    <ol>
      <li>Read error messages to <code class="language-plaintext highlighter-rouge">understand the problem</code></li>
      <li><code class="language-plaintext highlighter-rouge">Isolate</code> the method with fake data</li>
      <li>Send made-up data into the method with fake data</li>
      <li>Know how to solve common problems</li>
    </ol>
  </li>
  <li>The most common problem tends to be <code class="language-plaintext highlighter-rouge">tensor shape</code>
    <ul>
      <li>Tensor shape</li>
      <li>Scalar-vector mismatch</li>
      <li>Data type mismatch</li>
    </ul>
  </li>
  <li>Shape problems also happen because of <code class="language-plaintext highlighter-rouge">batch size</code> or because <strong>you have a scalar when a vector is needed</strong> (or vice versa)</li>
  <li>Shape problems can often be fixed using
    <ol>
      <li>tf.reshape()</li>
      <li>tf.expand_dims()</li>
      <li>tf.slice()</li>
      <li>tf.squeeze()</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">tf.expand_dims</code> inserts a dimension of 1 into a tensor’s shape</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">3.</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
<span class="k">print</span> <span class="s">"x.shape"</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"expanded.shape"</span><span class="p">,</span> <span class="n">expanded</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="s">"expanded:</span><span class="se">\n</span><span class="s">"</span><span class="p">:,</span> <span class="n">expanded</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>

<span class="c1"># OUTPUT:
# x.shape (3, 2)
# expanded.shape (3, 1, 2)
# expanded:
# [[[3 2]]
#  [[4 5]]
#  [[6 7]]]</span></code></pre></figure>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.slice</code> extracts a slice from a tensor</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">3.</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
<span class="k">print</span> <span class="s">"x.shape"</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">sliced</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nb">slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"sliced.shape"</span><span class="p">,</span> <span class="n">sliced</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="s">"sliced:</span><span class="se">\n</span><span class="s">:"</span><span class="p">,</span> <span class="n">sliced</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>

<span class="c1"># OUTPUT:
# x.shape (3, 2)
# sliced.shape (2, 1)
# sliced:
# [[2]
#  [5]]</span></code></pre></figure>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.squeeze</code> removes dimensions of size 1 from the shape of a tensor</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">]],[[</span><span class="mi">5</span><span class="p">],[</span><span class="mi">6</span><span class="p">],[</span><span class="mi">7</span><span class="p">],[</span><span class="mi">8</span><span class="p">]]])</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="s">"t"</span><span class="p">)</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="s">"t squeezed"</span><span class="p">)</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">t</span><span class="p">)))</span>

<span class="c1"># OUTPUT:
# t
# [[[1]
#   [2]
#   [3]
#   [4]]
#
#  [[5]
#   [6]
#   [7]
#   [8]]]
# t squeezed
# [[1 2 3 4]
#  [5 6 7 8]]</span></code></pre></figure>

<ul>
  <li>Another common problem is <code class="language-plaintext highlighter-rouge">data type</code>
    <ul>
      <li>The reason is because we are <code class="language-plaintext highlighter-rouge">mixing types</code>.(ex. Adding a tensor of floats to a tensor of ints won’t work)</li>
      <li>One solution is to do a cast with <code class="language-plaintext highlighter-rouge">tf.cast()</code>.</li>
    </ul>
  </li>
</ul>

<hr />

<ul>
  <li>To debug full-blown programs. there are three methods
    <ul>
      <li><code class="language-plaintext highlighter-rouge">tf.Print()</code></li>
      <li><code class="language-plaintext highlighter-rouge">tfdbg</code></li>
      <li><code class="language-plaintext highlighter-rouge">TensorBoard</code></li>
    </ul>
  </li>
  <li>Change logging level from <code class="language-plaintext highlighter-rouge">WARN</code></li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">tf</span><span class="p">.</span><span class="n">logging</span><span class="p">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">logging</span><span class="p">.</span><span class="n">INFO</span><span class="p">)</span></code></pre></figure>

<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.Print()</code> can be used to log specific tensor values</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">some_method</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="err">​</span>	<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">/</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># oops! NaN
</span><span class="err">​</span>	<span class="n">print_ab</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Print</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
<span class="err">​</span>	<span class="n">s</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">is_nan</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>
<span class="err">​</span>	<span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="n">fake_a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">]])</span>
<span class="err">​</span>	<span class="n">fake_b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
<span class="err">​</span>	<span class="k">print</span><span class="p">(</span><span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">some_method</span><span class="p">(</span><span class="n">fake_a</span><span class="p">,</span> <span class="n">fake_b</span><span class="p">))</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">bash</span>
<span class="n">python</span> <span class="n">xyz</span><span class="p">.</span><span class="n">py</span>

<span class="n">Output</span><span class="p">:</span>
<span class="p">[[</span> <span class="n">nan</span>     <span class="n">nan</span><span class="p">][</span> <span class="n">nan</span> <span class="mf">1.43365264</span><span class="p">]]</span></code></pre></figure>

<ul>
  <li>TensorFlow has a dynamic, interactive debugger (<code class="language-plaintext highlighter-rouge">tfdbg</code>)</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="k">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">python</span> <span class="n">impoty</span> <span class="n">debug</span> <span class="k">as</span> <span class="n">tf_debug</span>

<span class="k">def</span> <span class="nf">some_method</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="err">​</span>	<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">s</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">/</span> <span class="n">b</span><span class="p">)</span> <span class="c1"># oops! NaN
</span><span class="err">​</span>	<span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">s</span><span class="p">)))</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="err">​</span>	<span class="n">fake_a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.1</span><span class="p">,</span> <span class="mf">4.8</span><span class="p">]])</span>
<span class="err">​</span>	<span class="n">fake_b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>

	<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">debug</span><span class="p">.</span><span class="n">LocalCLIDegubWrapperSession</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
	<span class="n">sess</span><span class="p">.</span><span class="n">add_tensor_filter</span><span class="p">(</span><span class="s">"has_inf_or_nan"</span><span class="p">,</span> <span class="n">tf_debug</span><span class="p">.</span><span class="n">has_inf_or_nan</span><span class="p">)</span>
	<span class="k">print</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">some_method</span><span class="p">(</span><span class="n">fake_a</span><span class="p">,</span> <span class="n">fake_b</span><span class="p">)</span>

<span class="c1"># in a Terminal window
# python xyz.py --debug</span></code></pre></figure>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href="https://cyc1am3n.github.io">Daeyoung Kim</a>.
  </div>
</footer>

  </div>
</body>

</html>