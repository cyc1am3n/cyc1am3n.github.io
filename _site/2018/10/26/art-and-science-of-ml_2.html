<!DOCTYPE html>
<html lang="en">
<head>
  <!-- <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Coursera] Art and Science of Machine Learning (2) | Daeyoung Kim</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="[Coursera] Art and Science of Machine Learning (2)" />
<meta name="author" content="cyc1am3n" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 다섯 번째 코스인 Art and Science of Machine Learning의 강의노트입니다." />
<meta property="og:description" content="Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 다섯 번째 코스인 Art and Science of Machine Learning의 강의노트입니다." />
<link rel="canonical" href="http://localhost:4000/2018/10/26/art-and-science-of-ml_2.html" />
<meta property="og:url" content="http://localhost:4000/2018/10/26/art-and-science-of-ml_2.html" />
<meta property="og:site_name" content="Daeyoung Kim" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-26T17:50:54+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[Coursera] Art and Science of Machine Learning (2)" />
<meta name="twitter:site" content="@daeyoung__k" />
<meta name="twitter:creator" content="@cyc1am3n" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"cyc1am3n"},"dateModified":"2018-10-26T17:50:54+09:00","datePublished":"2018-10-26T17:50:54+09:00","description":"Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 다섯 번째 코스인 Art and Science of Machine Learning의 강의노트입니다.","headline":"[Coursera] Art and Science of Machine Learning (2)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/10/26/art-and-science-of-ml_2.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/smile.png"},"name":"cyc1am3n"},"url":"http://localhost:4000/2018/10/26/art-and-science-of-ml_2.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav>
      <ul>
        
        <!-- others -->
        <a href="/">
          <li class="btn-nav">Home</li>
        </a>
        
        
        
          <a href="/blog">
            <li class="current btn-nav">Blog</li>
          </a>
          <a href="/tags">
            <li class="btn-nav">Tags</li>
          </a>
        
        
      </ul>
    </nav>
  </header>
</section>
<div id="post">
  <section class="post-header">
    <h1 class="title">[Coursera] Art and Science of Machine Learning (2)</h1>
    <p class="subtitle">Machine Learning with TensorFlow on GCP</p>
    <p class="meta">
      October 26, 2018
    </p>
  </section>
  <section class="post-content">
    <p>Coursera 강의 “Machine Learning with TensorFlow on Google Cloud Platform” 중 다섯 번째 코스인 <a href="https://www.coursera.org/learn/art-science-ml/home/welcome">Art and Science of Machine Learning</a>의 강의노트입니다.</p>

<hr />

<p><br /></p>

<h2 id="review-embedding">Review Embedding</h2>

<hr />

<ul>
  <li>Creating an embedding column from a <code class="language-plaintext highlighter-rouge">feature cross</code>.</li>
  <li>The weights in the embedding column are <code class="language-plaintext highlighter-rouge">learned from data</code>.</li>
  <li>The model learns how to embed the feature cross in lower-dimensional space</li>
  <li>Embedding a feature cross in TensorFlow</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="kn">import</span> <span class="nn">tf.feature_column</span> <span class="k">as</span> <span class="n">fc</span>

<span class="n">day_hr</span> <span class="o">=</span> <span class="n">fc</span><span class="p">.</span><span class="n">crossed_column</span><span class="p">([</span><span class="n">dayofweek</span><span class="p">,</span> <span class="n">hourofday</span><span class="p">],</span> <span class="mi">24</span><span class="o">*</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># Transfer Learning of embedding from similar ML models
</span><span class="n">day_hr_em</span> <span class="o">=</span> <span class="n">fc</span><span class="p">.</span><span class="n">embedding_column</span><span class="p">(</span><span class="n">day_hr</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">ckpt_to_load_from</span><span class="o">=</span><span class="s">'london/*ckpt-1000*'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">tensor_name_in_ckpt</span><span class="o">=</span><span class="s">'dayhr_embed'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">trainable</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span></code></pre></figure>

<ul>
  <li>Transfer Learning of embeddings from similar ML models
    <ul>
      <li>First layer: the feature cross</li>
      <li>Second layer: a mystery box labeled latent factor</li>
      <li>Third layer: the embedding</li>
      <li>Fourth layer: one side: image of traffic</li>
      <li>Second side: image of people watching TV</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="recommendations">Recommendations</h2>

<hr />

<ul>
  <li>Using a <code class="language-plaintext highlighter-rouge">second dimension</code> gives us more freedom in organizing movies by similarity</li>
  <li>A <code class="language-plaintext highlighter-rouge">d-dimensional</code> embedding assumes that user interest in movies can be approximated by d aspects (d &lt; N)</li>
</ul>

<p><img src="/img/posts/art-and-science-of-ml/14.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<p><br /></p>

<h2 id="data-driven-embeddings">Data-driven Embeddings</h2>

<hr />

<ul>
  <li>We could give the axes names, but it is not essential</li>
  <li>Its’ easier to train a model with d inputs than a model with N inputs</li>
  <li>Embeddings can be learned from data</li>
</ul>

<p><img src="/img/posts/art-and-science-of-ml/15.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<p><br /></p>

<h2 id="sparse-tensors">Sparse Tensors</h2>

<hr />

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">Dense</code> representations are inefficient in space and compute</p>
  </li>
  <li>
    <p>So, use a <code class="language-plaintext highlighter-rouge">sparse representation</code> to hold the example</p>

    <ul>
      <li>Build a dictionary mapping each feature to an integer from 0, … # movies -1</li>
      <li>Efficiently represent the sparse vector as just the movies the user watched</li>
    </ul>
  </li>
  <li>
    <p>Representing feature columns as sparse vectors (These are all different ways to create a categorical column)</p>

    <ul>
      <li>If you <code class="language-plaintext highlighter-rouge">know the keys</code> beforehand:</li>
    </ul>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_column_with_vocabulary_list</span><span class="p">(</span><span class="s">'employeeId'</span><span class="p">,</span>
  <span class="err">​</span>	<span class="n">vocabulary_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">'8345'</span><span class="p">,</span> <span class="s">'72345'</span><span class="p">,</span> <span class="s">'87654'</span><span class="p">,</span> <span class="s">'98723'</span><span class="p">,</span> <span class="s">'23451'</span><span class="p">])</span>
  </code></pre></figure>

<ul>
  <li>If your data is <code class="language-plaintext highlighter-rouge">already indexed</code>: i.e., has integers in[0-N):</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_column_with_identity</span><span class="p">(</span><span class="s">'employeeId'</span><span class="p">,</span>
  <span class="err">​</span>	<span class="n">num_bucket</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
  </code></pre></figure>

<ul>
  <li>If you don’t have a vocabulary of all possible values:</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="n">tf</span><span class="p">.</span><span class="n">feature_column</span><span class="p">.</span><span class="n">categorical_column_with_hash_bucket</span><span class="p">(</span><span class="s">'employeeId'</span><span class="p">,</span>
<span class="err">​</span>	<span class="n">hash_bucket_size</span> <span class="o">=</span> <span class="mi">500</span><span class="p">)</span></code></pre></figure>

<p><br /></p>

<h2 id="train-an-embedding">Train an Embedding</h2>

<hr />

<ul>
  <li>Embedding are feature columns that function like layers</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="n">sparse_word</span> <span class="o">=</span> <span class="n">fc</span><span class="p">.</span><span class="n">categorical_column_with_vocabulary_list</span><span class="p">(</span><span class="s">'word'</span><span class="p">,</span>
<span class="err">​</span>	<span class="n">vocabulary_list</span><span class="o">=</span><span class="n">englishWords</span><span class="p">)</span>
<span class="n">embedded_word</span> <span class="o">=</span> <span class="n">fc</span><span class="p">.</span><span class="n">embedding_column</span><span class="p">(</span><span class="n">sparse_word</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>The weights in the embedding layer are learned through <code class="language-plaintext highlighter-rouge">backprop</code> just as with other weights</li>
  <li>Embeddings can be thought of as <code class="language-plaintext highlighter-rouge">latent features</code>.</li>
</ul>

<p><img src="/img/posts/art-and-science-of-ml/16.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<p><br /></p>

<h2 id="similarity-property">Similarity Property</h2>

<hr />

<ul>
  <li>Embeddings provides <code class="language-plaintext highlighter-rouge">dimensionality reduction</code>.</li>
</ul>

<p><img src="/img/posts/art-and-science-of-ml/17.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<ul>
  <li>
    <p>You can take advantage of this similarity property of embeddings</p>
  </li>
  <li>
    <p>A good starting point for number of embedding dimensions</p>

    <ul>
      <li>Higher dimensions → <code class="language-plaintext highlighter-rouge">more accuracy</code></li>
      <li>Higher dimensions → <code class="language-plaintext highlighter-rouge">overfitting</code>, <code class="language-plaintext highlighter-rouge">slow training</code></li>
      <li>Empirical tradeoff</li>
    </ul>

\[dimensions\approx\sqrt[4]{possible\ values}\]
  </li>
</ul>

<p><br /></p>

<h2 id="custom-estimator">Custom Estimator</h2>

<hr />

<ul>
  <li>Estimator provides a lot of benefits</li>
  <li>Canned Estimators are sometimes insufficient</li>
</ul>

<p><img src="/img/posts/art-and-science-of-ml/18.png" alt="" class="center-75" /><br />
<span class="caption"></span></p>

<ul>
  <li>
    <p>Suppose that you want to use a model structure from a research paper…</p>

    <ul>
      <li>Implement the model using low-level TensorFlow ops</li>
    </ul>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="k">def</span> <span class="nf">model_from_research_paper</span><span class="p">(</span><span class="n">timeseries</span><span class="p">):</span>
  <span class="err">​</span>	<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">timeseries</span><span class="p">,</span> <span class="n">N_INPUTS</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
  <span class="err">​</span>	<span class="n">lstm_cell</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">LSTM_SIZE</span><span class="p">,</span> <span class="n">forget_bias</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="err">​</span>	<span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">.</span><span class="n">static_rnn</span><span class="p">(</span><span class="n">lstm_cell</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="err">​</span>	<span class="n">outputs</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="err">​</span>	<span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">([</span><span class="n">LSTM_SIZE</span><span class="p">,</span> <span class="n">N_OUTPUTS</span><span class="p">]))</span>
  <span class="err">​</span>	<span class="n">bias</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal</span><span class="p">[</span><span class="n">N_OUTPUTS</span><span class="p">]))</span>
  <span class="err">​</span>	<span class="n">predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias</span>
  <span class="err">​</span>	<span class="k">return</span> <span class="n">predictions</span>
  </code></pre></figure>

<ul>
  <li>
    <p>How do we wrap this custom model into Estimator framework?</p>
  </li>
  <li>
    <p>Create <code class="language-plaintext highlighter-rouge">train_and_evaluate function</code> with the base-class Estimator</p>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="p">...):</span>
<span class="err">​</span>	<span class="n">estimator</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimators</span><span class="p">.</span><span class="n">Estimator</span><span class="p">(</span><span class="n">model_fn</span> <span class="o">=</span> <span class="n">myfunc</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">model_dir</span> <span class="o">=</span> <span class="n">output_dir</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">train_spec</span> <span class="o">=</span> <span class="n">get_train</span><span class="p">()</span>
<span class="err">​</span>	<span class="n">exporter</span> <span class="o">=</span> <span class="p">...</span>
<span class="err">​</span>	<span class="n">eval_spec</span> <span class="o">=</span> <span class="n">get_valid</span><span class="p">()</span>
<span class="err">​</span>	<span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">train_spec</span><span class="p">,</span> <span class="n">eval_spec</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>
    <p>myfunc (above) is a <code class="language-plaintext highlighter-rouge">EstimatorSpec</code>.</p>

    <ul>
      <li>The 6 things in a EstimatorSpec</li>
    </ul>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">Mode</code> is pass-through</li>
      <li>Any tensors you want to return</li>
      <li><code class="language-plaintext highlighter-rouge">Loss</code> metric</li>
      <li><code class="language-plaintext highlighter-rouge">Training</code> op</li>
      <li><code class="language-plaintext highlighter-rouge">Eval</code> ops</li>
      <li>Export outputs</li>
    </ol>
  </li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="k">def</span> <span class="nf">myfunc</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
  	<span class="c1"># Code up the model
</span>  <span class="err">​</span>	<span class="n">predictions</span> <span class="o">=</span> <span class="n">model_from_research_paper</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">INCOL</span><span class="p">})</span>

  <span class="c1"># Set up loss function, training/eval ops
</span>  <span class="p">...</span> <span class="c1"># (next code)
</span>
  <span class="c1"># Create export outputs
</span>  <span class="n">export_outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"regression_export_outputs"</span><span class="p">:</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">export</span><span class="p">.</span><span class="n">RegressionOutput</span><span class="p">(</span><span class="n">value</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">)}</span>
  <span class="c1"># Return EstimatorSpec
</span>  <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">EstimatorSpec</span><span class="p">(</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="p">,</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions_dict</span><span class="p">,</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">,</span>
  <span class="n">train_op</span> <span class="o">=</span> <span class="n">train_op</span><span class="p">,</span>
  <span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="n">eval_metric_ops</span><span class="p">,</span>
  <span class="n">export_outputs</span> <span class="o">=</span> <span class="n">export_outputs</span><span class="p">)</span>

  </code></pre></figure>

<ul>
  <li>The ops are set up in the appropriate mode</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">ModeKeys</span><span class="p">.</span><span class="n">TRAIN</span> <span class="ow">or</span>
<span class="err">​</span>	<span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">ModeKeys</span><span class="p">.</span><span class="n">EVAL</span><span class="p">:</span>
<span class="err">​</span>	<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">optimize_loss</span><span class="p">(</span>
<span class="err">​</span>		<span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">framework</span><span class="p">.</span><span class="n">get_global_step</span><span class="p">(),</span>
<span class="err">​</span>		<span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">optimizer</span><span class="o">=</span><span class="s">"SGD"</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="p">{</span>
<span class="err">​</span>		<span class="s">"rmse"</span> <span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)}</span>
<span class="k">else</span><span class="p">:</span>
<span class="err">​</span>	<span class="n">loss</span> <span class="o">=</span> <span class="bp">None</span>
<span class="err">​</span>	<span class="n">train_op</span> <span class="o">=</span> <span class="bp">None</span>
<span class="err">​</span>	<span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="bp">None</span></code></pre></figure>

<p><br /></p>

<h2 id="keras-models">Keras Models</h2>

<hr />

<ul>
  <li>Keras is high-level deep neural networks library that supports multiple backends</li>
  <li>Keras is easy to use for fast prototyping</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>From a compiled Keras model, you can get an Estimator</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">max_features</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">256</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">optimizer</span><span class="o">=</span><span class="s">'rmsprop'</span><span class="p">,</span>
<span class="err">​</span>		<span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="c1"># Get estimator from keras
</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">model_to_estimator</span><span class="p">(</span><span class="n">keras_model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>You will use this estimator the way you normally use an estimator</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
<span class="err">​</span>	<span class="n">estimator</span> <span class="o">=</span> <span class="n">make_keras_estimator</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">train_spec</span> <span class="o">=</span> <span class="n">tflestimator</span><span class="p">.</span><span class="n">TrainSpec</span><span class="p">(</span><span class="n">train_fn</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">exporter</span> <span class="o">=</span> <span class="n">LatestExporter</span><span class="p">(</span><span class="s">'exporter'</span><span class="p">,</span> <span class="n">serving_input_fn</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">eval_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">EvalSpec</span><span class="p">(</span><span class="n">eval_fn</span><span class="p">,</span>
<span class="err">​</span>				<span class="n">steps</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
<span class="err">​</span>				<span class="n">exporters</span> <span class="o">=</span> <span class="n">exporter</span><span class="p">)</span>
<span class="err">​</span>	<span class="n">tf</span><span class="p">.</span><span class="n">estimator</span><span class="p">.</span><span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">train_spec</span><span class="p">,</span> <span class="n">eval_spec</span><span class="p">)</span></code></pre></figure>

<ul>
  <li>The connection between the input features and Keras is through a naming convention</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> 
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(...,</span> <span class="n">name</span><span class="s">'XYZ'</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">train_input_fn</span><span class="p">():</span>
<span class="err">​</span>	<span class="p">...</span>
<span class="err">​</span>	<span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
<span class="err">​</span>				<span class="s">'XYZ_input'</span><span class="p">:</span> <span class="n">some_tensor</span><span class="p">,</span>
<span class="err">​</span>			<span class="p">}</span>
<span class="err">​</span>	<span class="k">return</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span></code></pre></figure>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href="https://cyc1am3n.github.io">Daeyoung Kim</a>.
  </div>
</footer>

  </div>
</body>

</html>