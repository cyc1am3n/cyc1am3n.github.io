<!DOCTYPE html>
<html lang="en">
<head>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  
  <!-- Favicon code from realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#8b51a3">
<meta name="msapplication-TileColor" content="#563d7c">
<meta name="theme-color" content="#ffffff">

  <!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Fonts & Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
  <link href='//spoqa.github.io/spoqa-han-sans/css/SpoqaHanSans-kr.css' rel='stylesheet' type='text/css'>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Machine Learning] Logistic Regression | Daeyoung Kim</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="[Machine Learning] Logistic Regression" />
<meta name="author" content="cyc1am3n" />
<meta property="og:locale" content="en_GB" />
<meta name="description" content="* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다." />
<meta property="og:description" content="* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다." />
<link rel="canonical" href="http://localhost:4000/computerscience/2018/04/10/logistic-regression.html" />
<meta property="og:url" content="http://localhost:4000/computerscience/2018/04/10/logistic-regression.html" />
<meta property="og:site_name" content="Daeyoung Kim" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-04-10T17:30:54+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="[Machine Learning] Logistic Regression" />
<meta name="twitter:site" content="@daeyoung__k" />
<meta name="twitter:creator" content="@cyc1am3n" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"cyc1am3n"},"dateModified":"2018-04-10T17:30:54+09:00","datePublished":"2018-04-10T17:30:54+09:00","description":"* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 Machine Learning(링크)를 바탕으로 작성되었습니다.","headline":"[Machine Learning] Logistic Regression","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/computerscience/2018/04/10/logistic-regression.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/smile.png"},"name":"cyc1am3n"},"url":"http://localhost:4000/computerscience/2018/04/10/logistic-regression.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<!--jQuery-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
<body>
  <div class="container">
    

<section id="header-nav">
  <header>
    <nav>
      <ul>
        
        <!-- others -->
        <a href="/">
          <li class="btn-nav">Home</li>
        </a>
        
        
        
          <a href="/blog">
            <li class="current btn-nav">Blog</li>
          </a>
          <a href="/tags">
            <li class="btn-nav">Tags</li>
          </a>
        
        
      </ul>
    </nav>
  </header>
</section>
<div id="post">
  <section class="post-header">
    <h1 class="title">[Machine Learning] Logistic Regression</h1>
    <p class="subtitle">「 Machine Learning 」 lecture summary #5</p>
    <p class="meta">
      April 10, 2018
    </p>
  </section>
  <section class="post-content">
    <p>* 이 포스트는 Coursera에 있는 Andrew Ng 교수님의 강의 <a href="https://www.coursera.org/learn/machine-learning">Machine Learning(링크)</a>를 바탕으로 작성되었습니다.</p>

<h2 id="classification">Classification</h2>

<p>지금까지 공부해본 regression과 달리 classification에서는 <code class="language-plaintext highlighter-rouge">discrete value</code>를 다룬다.</p>

<p>제일 간단한 방법은 모든 data 값을 0과 1 사이에 mapping 시키고 그 값이 0.5를 기준으로 작으면 0, 크면 1 이라고 예측하는 것이다.</p>

<p>하지만 모든 케이스가 linear한 형태를 띄고 있지는 않으므로 이 방법보단 기준 값을 두어 일정 값 이상이면 1 이라고 예측하는 방법을 주로 사용한다.</p>

<p>한편, 위에서도 언급했던 것 처럼 classification 문제는 예측할 값이 discrete value라는 걸 빼면 regression 과 비슷하다.</p>

<p>일단 예측 결과 값 y가 두 가지 값(0, 1; 각 케이스rable을 만든다) 밖에 가질 수 없는 binary classification에 대해서 생각해보자.(여기서 multiple classification으로도 일반화 시킬 수 있다.)</p>

<p>예를 들면,</p>
<blockquote>
  <p>· 환자의 종양이 악성인지(0 또는 1) / 아닌지(1 또는 0)<br />
 · 메일이 스팸인지(0 또는 1) / 아닌지(1 또는 0)</p>
</blockquote>

<p>등이 있다.</p>

<h2 id="hypothesis-representation">Hypothesis Representation</h2>

<p>Classification은 data값을 0과 1사이에 mapping 시켜 이루어진다고 했는데, 이렇게 mapping 시키는 함수를 <code class="language-plaintext highlighter-rouge">hypothesis function</code>이라 한다.</p>

<p>하지만 모든 데이터의 값에 비례해 linear regression과 같은 방식으로 hypothesis function을 만들면 좋은 예측을 할 수 없다.</p>

<p>이를 해결하기 위해  <code class="language-plaintext highlighter-rouge">Logistic Function</code>, 혹은 <code class="language-plaintext highlighter-rouge">Sigmoid Function</code> 이라는 함수를 이용하는데, 이는 다음과 같다.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/01.png" alt="그림1" width="30%" height="30%" /></p>

<p>이러한 sigmoid function의 그래프는 아래와 같다.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/02.png" alt="그림2" width="70%" height="70%" /></p>

<p>이 함수 g(z)는 결과가 1이 나올 확률을 나타낸다.</p>

<p>예를 들면, 위 함수에서 g(z) = 0.7 일 때 y = 1일 확률이 70 %가 된다는 것이다.</p>

<p>또한 결과가 1이 나올 확률과 0이 나올 확률의 합은 항상 1이므로 결과에 따른 확률도 다음과 같이 표현 가능하다.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/03.png" alt="그림3" width="60%" height="60%" /></p>

<h2 id="decison-boundary">Decison Boundary</h2>

<p>위의 과정을 통해 0 또는 1로 classification 하기 위해서, hypothesis function의 결과값을 다음으로 나타낼 수 있다.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/04.png" alt="그림4" width="100%" height="100%" /></p>

<p>logistic function을 생각해보면 결국 다음과 같다는 것도 알 수 있을 것이다.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/05.png" alt="그림5" width="100%" height="100%" /></p>

<p>이렇게 결과 값을 0 또는 1로 구별하는 지점을 <code class="language-plaintext highlighter-rouge">decision boundary</code>라고 하는데, 다음의 예를 살펴보자.</p>

<p>다음과 같은 두 class가 있을때, 이 class를 구분하는 decision boundary를 찾기 위해 hypothesis function h(x) = g(θ<sub>0</sub> + θ<sub>1</sub>x<sub>1</sub> + θ<sub>2</sub>x<sub>2</sub>)를 만들어 보자.</p>

<p style="text-align: center;"><img src="/img/posts/logistic-regression/06.png" alt="그림6" width="100%" height="100%" /></p>

<p>이때 θ = {-3, 1, 1}로 잡으면 x로 표시된 부분은 y = 1이 될 것이고, o로 표시된 부분은 y = 0이 될 것이다.</p>

<p>이렇게 g(z) = 0, 즉 h(x) = 0.5를 만족시키는 부분을 Decision boundary 라고 한다.</p>

  </section>
</div>

<div id="top" class="top-btn" onclick="moveTop()">
  <i class="fas fa-chevron-up"></i>
</div>

<script>
  var lastScrollTop = 0;
  window.onscroll = function () {
    var st = document.body.scrollTop || document.documentElement.scrollTop;
    if (st > 250) {
      document.getElementById("top").style.display = "block"
      if (st > lastScrollTop) {
        document.getElementById("top").style.opacity = 0
      } else {
        document.getElementById("top").style.opacity = 1
      }
    } else {
      document.getElementById("top").style.opacity = 0
      if (st > lastScrollTop) {
        document.getElementById("top").style.display = "none"
      }
    }
    lastScrollTop = st <= 0 ? 0 : st;
  }
  function moveTop() {
    document.body.scrollTop = 0
    document.documentElement.scrollTop = 0
  }
</script>

<!-- Footer -->
<footer>
  <div class="footer">
    Copyright © 2022
    <a href="https://cyc1am3n.github.io">Daeyoung Kim</a>.
  </div>
</footer>

  </div>
</body>

</html>